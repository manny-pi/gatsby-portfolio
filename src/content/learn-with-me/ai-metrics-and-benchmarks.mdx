---
title: "AI Metrics and Benchmarks"
date: "2024-01-27"
slug: "ai-metrics-and-benchmarks"
app: "learn-with-me"
---

Evaluating the performance of ML models, applied to any domain, is tricky. Magnifying this problem is 
the ecosystem of metrics and benchmarks that just seems to keep *growing*. In fact, some 
measures of model performance are entirely useless and only apply to the niche and sparsely reproducable problems
that were studied to create them in the first place. This makes it all more difficult to know whether or not a 
model is good, and whether or not your models performance based on a particular metric should be taken seriously.

However, it's still very important to determine how well a model is performing, and there are several domain-specific
metrics that are useful for doing so. So, I've compiled a list of metrics and bencharks that I've found to 
be non-useless. I've evaluated some of my models using these metrics, and the scores my models achieved have
held "held true" in the wild. So, these aren't just based off some academic reading I've done. 


# What is a Metric?

# What is a Benchmark? 



